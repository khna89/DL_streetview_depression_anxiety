{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOcXy2_xKkRH"
      },
      "source": [
        "# Setting the ground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UEdrGtJE5N4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, Subset, WeightedRandomSampler\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import os\n",
        "from random import randint\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.metrics import f1_score\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.models.resnet import ResNet50_Weights\n",
        "import cv2\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkazGaxeGQbx"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "drive.mount( '/content/drive', force_remount=True )\n",
        "os.chdir(\"/content/drive/MyDrive/\") #change the path so that it leads to your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ2KYFuJLPoM",
        "outputId": "fa8ecbe6-df64-4872-b31e-9da48409f6dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.8-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.18.0 safetensors-0.4.0 timm-0.9.8\n"
          ]
        }
      ],
      "source": [
        "!pip install timm #you need to install it every time in the cloud to work with DeiT models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK1DhFQOlun8"
      },
      "source": [
        "# For continuous targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x8ZeaqsKoxb"
      },
      "source": [
        "### Loading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnazFRuIzwHZ"
      },
      "source": [
        "CustomDataset class that is adjusted to load the images with continuous targets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY4zJii_zCnK"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, df, img_folder, transform=None):\n",
        "        self.df = df\n",
        "        self.img_folder = img_folder\n",
        "        self.transform = transform\n",
        "        self.min_target = self.df['high_risk'].min()\n",
        "        self.max_target = self.df['high_risk'].max()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.df.iloc[index]['file_name']\n",
        "        img_path = os.path.join(self.img_folder, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        target = self.df.iloc[index, 4]\n",
        "        #target_normalized = (target - self.min_target) / (self.max_target - self.min_target) #can also try this\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(target, dtype=torch.float) #torch.tensor(target_normalized, dtype=torch.float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0pgq4i_z-Q6"
      },
      "outputs": [],
      "source": [
        "# Define the data transforms necessary for the network that's being used\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA5WjLP8z5f-"
      },
      "outputs": [],
      "source": [
        "# Read the csv file\n",
        "df = pd.read_csv('disp_coords.csv')\n",
        "\n",
        "# Shuffle the DataFrame\n",
        "df = df.sample(frac=1)\n",
        "\n",
        "# Calculate sizes of each split\n",
        "train_size = int(len(df) * 0.7) #set to less for hyperparameter selection\n",
        "val_size = int(len(df) * 0.15)\n",
        "\n",
        "# Split the data\n",
        "train_df, val_df, test_df = np.split(df, [train_size, train_size + val_size])\n",
        "\n",
        "# Save the indices\n",
        "torch.save(train_df.index.values, 'train_indices_continuous_tiny.pt')\n",
        "torch.save(val_df.index.values, 'val_indices_continuous_tiny.pt')\n",
        "torch.save(test_df.index.values, 'test_indices_continuous_tiny.pt')\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = CustomDataset(train_df, './nl_svi_dispersed_green', transform=train_transforms) #set this to train_transforms for random crop\n",
        "val_dataset = CustomDataset(val_df, './nl_svi_dispersed_green', transform=val_transforms)\n",
        "test_dataset = CustomDataset(test_df, './nl_svi_dispersed_green', transform=val_transforms)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=20, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdnaVwaG7Gwk"
      },
      "source": [
        "### Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQ4mBO7h7I8q"
      },
      "outputs": [],
      "source": [
        "def train_custom_model(model_name, unfreeze_layers, optimizer_fn, lr, dropout_par, num_epochs, *args, **kwargs):\n",
        "    model = torch.hub.load('facebookresearch/deit:main', model_name, pretrained=True)\n",
        "\n",
        "    # Get the number of transformer layers\n",
        "    num_transformer_layers = len(model.blocks)\n",
        "\n",
        "    # Freeze all layers except the specified number of unfrozen layers\n",
        "    for i in range(num_transformer_layers - unfreeze_layers):\n",
        "        for param in model.blocks[i].parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    num_classes = 1\n",
        "    in_features = model.head.in_features\n",
        "\n",
        "    model.head = nn.Sequential(\n",
        "        nn.Dropout(dropout_par),\n",
        "        nn.BatchNorm1d(num_features=in_features),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_par),\n",
        "        nn.Linear(in_features, num_classes)\n",
        "    )\n",
        "    model = model.to(device)\n",
        "    #print(\"Model built.\")\n",
        "    # Define the loss function and optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optimizer_fn(model.parameters(), lr=lr, *args, **kwargs)\n",
        "\n",
        "    # Define the learning rate scheduler\n",
        "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5, verbose=True)\n",
        "\n",
        "    # Early stopping parameters\n",
        "    early_stopping_patience = 10\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    #custom metric to discretize the performance measurement\n",
        "    how_close = 2.6 #it's SD for our data, you can try different thresholds\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        train_loss = 0.0\n",
        "        train_approx_right = 0\n",
        "\n",
        "        model.train()\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs).squeeze()\n",
        "            loss = criterion(outputs, labels.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            # Calculate the custom metric\n",
        "            close_enough = torch.abs(outputs - labels.float()) <= how_close\n",
        "            train_approx_right += torch.sum(close_enough).item()\n",
        "\n",
        "        # Calculate average loss, MAE and MSE over one epoch\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_approx_acc = train_approx_right / len(train_loader.dataset)\n",
        "\n",
        "        # Validation\n",
        "        val_loss = 0.0\n",
        "        val_approx_right = 0\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # We won't need gradients for validation, so save memory and computation\n",
        "        with torch.no_grad():\n",
        "            for i, (inputs, labels) in enumerate(val_loader):\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs).squeeze()\n",
        "\n",
        "                # Compute loss\n",
        "                loss = criterion(outputs, labels.float())\n",
        "\n",
        "                # Update loss and acc\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                close_enough = torch.abs(outputs - labels.float()) <= how_close\n",
        "                val_approx_right += torch.sum(close_enough).item()\n",
        "\n",
        "        # Calculate average loss and acc over validation dataset\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_approx_acc = val_approx_right / len(val_loader.dataset)\n",
        "\n",
        "        # Learning rate scheduler step\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Print validation statistics\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], \\\n",
        "        Approx Train Acc: {train_approx_acc:.4f}, Avg MSE Train: {train_loss:.4f}, \\\n",
        "        Approx Val Acc: {val_approx_acc:.4f}, Avg MSE Val: {val_loss:.4f}')\n",
        "\n",
        "        # Check for early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        if epochs_without_improvement >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered, stopping at epoch\", epoch)\n",
        "            break\n",
        "    #return model #uncomment for full fine-tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4XLe1fGAAQR"
      },
      "source": [
        "### Model selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYj-ge-LwW-N"
      },
      "outputs": [],
      "source": [
        "m_names = ['deit_tiny_patch16_224', 'deit_small_patch16_224', 'deit_base_patch16_224']\n",
        "dropouts = [0, 0.2, 0.5, 0.7]\n",
        "to_unfreeze = [0,1,3,5]\n",
        "lr_s = [0.001, 0.005, 0.01]\n",
        "optimizers = [optim.Adam, optim.SGD, optim.Adagrad]\n",
        "\n",
        "for m_n in m_names:\n",
        "    for drop in dropouts:\n",
        "        for to_unfr in to_unfreeze:\n",
        "            for lr in lr_s:\n",
        "                for opt in optimizers:\n",
        "                    print(m_n, \"dropout:\", drop, \"layers:\", to_unfr, \"lr =\", lr, str(opt), end='\\n\\n')\n",
        "                    train_custom_model(m_n, to_unfr, opt, lr, drop, 15)\n",
        "                    print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U41Nkm3yuGTf"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otj3ee8puImt"
      },
      "source": [
        "Choose the model that shows the most progress, based on the previous section. Change the percenetage of the data used (in the Loading data section). Fill in the hyperparameters below, accounting for more data if necessary (increase dropout, L2 regularization,...)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuK1zZ7LvBOT"
      },
      "outputs": [],
      "source": [
        "model = train_custom_model('deit_base_patch16_224', 5, optim.Adagrad, 0.001, 0.2, 100, weight_decay=3e-4)\n",
        "torch.save(model.state_dict(), 'deit_continuous.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9BzXT5_R58M"
      },
      "source": [
        "# For discretized targets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading data"
      ],
      "metadata": {
        "id": "Hya1mLBsWD8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, df, img_folder, transform=None):\n",
        "        self.df = df\n",
        "        self.img_folder = img_folder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.df.iloc[index]['file_name']\n",
        "        img_path = os.path.join(self.img_folder, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        target = self.df.iloc[index]['discrete_target'] #use \"discrete_target\" for 4 bins data\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(target, dtype=torch.long)"
      ],
      "metadata": {
        "id": "aT73UsV-WDVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data transforms necessary for the network that's being used\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "bSUA1k6FWQPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the csv file\n",
        "df = pd.read_csv('green_disp_coords_orig_bins.csv')\n",
        "\n",
        "# Shuffle the DataFrame\n",
        "df = df.sample(frac=1)\n",
        "\n",
        "# Calculate sizes of each split\n",
        "train_size = int(len(df) * 0.7)\n",
        "val_size = int(len(df) * 0.15)\n",
        "\n",
        "# Split the data\n",
        "train_df, val_df, test_df = np.split(df, [train_size, train_size + val_size])\n",
        "\n",
        "# Save the indices\n",
        "torch.save(train_df.index.values, 'train_indices_orig_bins.pt')\n",
        "torch.save(val_df.index.values, 'val_indices_orig_bins.pt')\n",
        "torch.save(test_df.index.values, 'test_indices_orig_bins.pt')\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = CustomDataset(train_df, './nl_svi_dispersed_green', transform=train_transforms) #set this to train_transforms for random crop\n",
        "val_dataset = CustomDataset(val_df, './nl_svi_dispersed_green', transform=val_transforms)\n",
        "test_dataset = CustomDataset(test_df, './nl_svi_dispersed_green', transform=val_transforms)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=20, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "s5VKXEDNWUN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DeiT"
      ],
      "metadata": {
        "id": "-dA7UK6IVydw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFr0Mtk5OADL"
      },
      "source": [
        "### Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3ML3zUVSIij"
      },
      "outputs": [],
      "source": [
        "def train_custom_model(model_name, unfreeze_layers, optimizer_fn, lr, dropout_par, num_epochs, *args, **kwargs):\n",
        "    model = torch.hub.load('facebookresearch/deit:main', model_name, pretrained=True)\n",
        "\n",
        "    # Get the number of transformer layers\n",
        "    num_transformer_layers = len(model.blocks)\n",
        "\n",
        "    # Freeze all layers except the specified number of unfrozen layers\n",
        "    for i in range(num_transformer_layers - unfreeze_layers):\n",
        "        for param in model.blocks[i].parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    num_classes = 4\n",
        "    in_features = model.head.in_features\n",
        "\n",
        "    model.head = nn.Sequential(\n",
        "        nn.Dropout(dropout_par),\n",
        "        nn.BatchNorm1d(num_features=in_features),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_par),\n",
        "        nn.Linear(in_features, num_classes)\n",
        "    )\n",
        "    model = model.to(device)\n",
        "    #print(\"Model built.\")\n",
        "    # Define the loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optimizer_fn(model.parameters(), lr=lr, *args, **kwargs)\n",
        "\n",
        "    # Define the learning rate scheduler\n",
        "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5, verbose=True)\n",
        "\n",
        "    # Early stopping parameters\n",
        "    early_stopping_patience = 10\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        #print(\"Start epoch.\")\n",
        "        # Training\n",
        "        train_loss, train_correct, train_total, train_f1_total = 0.0, 0, 0, 0\n",
        "        model.train()\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            train_correct += torch.sum(preds == labels.data)\n",
        "            train_total += labels.size(0)\n",
        "            train_f1_total += f1_score(labels.cpu().detach(), preds.cpu().detach(), average='weighted') * labels.size(0)\n",
        "\n",
        "        train_loss /= train_total\n",
        "        train_acc = train_correct.item() / train_total\n",
        "        train_f1 = train_f1_total / train_total\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_correct, val_total, val_f1_total = 0.0, 0, 0, 0\n",
        "        model.eval()\n",
        "        #print(\"Started validation.\")\n",
        "        with torch.no_grad():\n",
        "            for i, (inputs, labels) in enumerate(val_loader):\n",
        "                #if i%10 == 0 and i !=0:\n",
        "                 # print(\"Batch\", i)\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                val_correct += torch.sum(preds == labels.data)\n",
        "                val_total += labels.size(0)\n",
        "                val_f1_total += f1_score(labels.cpu().detach(), preds.cpu().detach(), average='weighted') * labels.size(0)\n",
        "\n",
        "        val_loss /= val_total\n",
        "        val_acc = val_correct.item() / val_total\n",
        "        val_f1 = val_f1_total / val_total\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}],\\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
        "\n",
        "        # Check for early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        if epochs_without_improvement >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered, stopping at epoch\", epoch)\n",
        "            break\n",
        "    return model #comment this line for hyperparameter selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBTcPVGyHR7A"
      },
      "source": [
        "### Hyperparameter selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcsSVBCeHYuA"
      },
      "source": [
        "Below is the code to perform grid search. The hyperparameters include three types of the DeiT models, amount of layers to re-train, learning rates and optimizers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFsWiWAxHUdj"
      },
      "outputs": [],
      "source": [
        "m_names = ['deit_tiny_patch16_224', 'deit_small_patch16_224', 'deit_base_patch16_224']\n",
        "to_unfreeze = [0,1,3,5]\n",
        "lr_s = [0.001, 0.005, 0.01]\n",
        "optimizers = [optim.Adam, optim.SGD, optim.Adagrad]\n",
        "\n",
        "for m_n in m_names:\n",
        "  for to_unfr in to_unfreeze:\n",
        "    for lr in lr_s:\n",
        "      for opt in optimizers:\n",
        "        print(m_n, to_unfr, lr, str(opt), end='\\n\\n')\n",
        "        train_custom_model(m_n, to_unfr, opt, lr, 0)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oBZzwqmODsJ"
      },
      "source": [
        "### Train top-1 model with regularization and save weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHvlm89MWWMa"
      },
      "outputs": [],
      "source": [
        "model = train_custom_model('deit_base_patch16_224', 5, optim.SGD, 0.001, 0.2, 100, weight_decay=1e-4)\n",
        "torch.save(model.state_dict(), 'base_5_SGD_001_reg.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX1yYtYLOTLB"
      },
      "source": [
        "### For experiment with full landscapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn956Nc2cVlm"
      },
      "source": [
        "Code to conduct an experiment where the model is trained on the full landscapes, so the images are resized to the dimensions expected by the model and no random crop is used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9fLRZjVOWWI"
      },
      "outputs": [],
      "source": [
        "#this assumes you have already run the code above and thus only have to re-define the train part\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = CustomDataset(train_df, './nl_svi_dispersed_green', transform=val_transforms) #set this to val_transforms to avoid random crop\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXVXn6L8yzk2"
      },
      "source": [
        "#### Grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDlggVL2OY50"
      },
      "outputs": [],
      "source": [
        "m_names = ['deit_tiny_patch16_224', 'deit_small_patch16_224', 'deit_base_patch16_224']\n",
        "to_unfreeze = [0,1,3,5]\n",
        "lr_s = [0.001, 0.01]\n",
        "optimizers = [optim.Adam, optim.SGD, optim.RMSprop, optim.Adagrad]\n",
        "dropouts = [0, 0.2, 0.4]\n",
        "L2s = [0,1e-3]\n",
        "\n",
        "for to_unfr in to_unfreeze:\n",
        "  print(\"\\n{} LAYERS UNFROZEN\\n\".format(to_unfr))\n",
        "  for m_n in m_names:\n",
        "    for lr in lr_s:\n",
        "      for opt in optimizers:\n",
        "        for do in dropouts:\n",
        "          for w_d in L2s:\n",
        "            print(m_n, to_unfr, str(opt), lr, do, w_d, end='\\n\\n')\n",
        "            train_custom_model(m_n, to_unfr, opt, lr, do, 15, weight_decay=w_d)\n",
        "            print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84SPSSd8OG38"
      },
      "source": [
        "### To load later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-06EzgFRCppY"
      },
      "outputs": [],
      "source": [
        "custom_dataset = CustomDataset(pd.read_csv('green_dispersed_coords.csv'), './nl_svi_dispersed_green', transform=val_transforms)\n",
        "\n",
        "# Load the indices (when resuming)\n",
        "#train_indices = torch.load('train_indices_final.pt')\n",
        "#val_indices = torch.load('val_indices_final.pt')\n",
        "test_indices = torch.load('test_indices_resnet.pt')\n",
        "\n",
        "# Create the datasets using the loaded indices\n",
        "#train_dataset = Subset(custom_dataset, train_indices)\n",
        "#val_dataset = Subset(custom_dataset, val_indices)\n",
        "test_dataset = Subset(custom_dataset, test_indices)\n",
        "\n",
        "# Create data loaders\n",
        "#train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "#val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKX_cCDWFrSH"
      },
      "outputs": [],
      "source": [
        "#load the model\n",
        "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=False)\n",
        "\n",
        "# Get the number of transformer layers\n",
        "num_transformer_layers = len(model.blocks)\n",
        "\n",
        "# Freeze all layers except the specified number of unfrozen layers\n",
        "for i in range(num_transformer_layers - 5):\n",
        "    for param in model.blocks[i].parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "num_classes = 4\n",
        "in_features = model.head.in_features\n",
        "\n",
        "model.head = nn.Sequential(\n",
        "    nn.Dropout(),\n",
        "    nn.BatchNorm1d(num_features=in_features),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(),\n",
        "    nn.Linear(in_features, num_classes)\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "model.load_state_dict(torch.load('deit_on_resnet_sets.pth')) #and the other one is 'deit_on_resnet_sets.pth'\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKGInk1bOKYK"
      },
      "source": [
        "### Evaluation and preprocessing for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFvNjD3iUQUa"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "test_loss, test_correct, test_correct_adj, test_total, test_f1_total = 0.0, 0, 0, 0, 0\n",
        "\n",
        "model.eval()\n",
        "num_batches = len(test_loader)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        test_correct += torch.sum(preds == labels.data)\n",
        "        test_correct_adj += torch.sum(preds == labels.data)\n",
        "        test_correct_adj += torch.sum( (preds +1) == labels.data) #to compute adjusted acc, comment this for standard acc\n",
        "        test_correct_adj += torch.sum( (preds -1) == labels.data) #to compute adjusted acc, comment this for standard acc\n",
        "        test_total += labels.size(0)\n",
        "        test_f1_total += f1_score(labels.cpu().detach(), preds.cpu().detach(), average='weighted') * labels.size(0)\n",
        "\n",
        "test_loss /= num_batches\n",
        "test_acc = test_correct.item() / test_total\n",
        "test_acc_adj = test_correct_adj.item() / test_total\n",
        "test_f1 = test_f1_total / test_total\n",
        "\n",
        "print('Test performance:')\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.5f}, Test Adj Acc: {test_acc_adj:.5f}, Test F1: {test_f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njiN9qDWUdva"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def imshow(img):\n",
        "    img = img * torch.tensor([0.229, 0.224, 0.225])[:, None, None] + torch.tensor([0.485, 0.456, 0.406])[:, None, None]  # Unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(30, 3))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "test_loss, test_correct, test_total, test_f1_total = 0.0, 0, 0, 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for batch_index, (inputs, labels) in enumerate(test_loader):\n",
        "    if batch_index == 0:  # Only take the first batch\n",
        "        inputs, labels = inputs[10:20].to(device), labels[10:20].to(device)  # Select the first 10 examples\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        test_correct += torch.sum(preds == labels.data)\n",
        "        test_total += labels.size(0)\n",
        "        test_f1_total += f1_score(labels.cpu().detach(), preds.cpu().detach(), average='weighted') * labels.size(0)\n",
        "        print('preds:', preds)\n",
        "        print('labels:',labels.data)\n",
        "\n",
        "        inputs_cpu = inputs.cpu()\n",
        "        imshow(torchvision.utils.make_grid(inputs_cpu, nrow=10))\n",
        "    else:\n",
        "      break\n",
        "\n",
        "test_acc = test_correct.item() / test_total\n",
        "test_f1 = test_f1_total / test_total\n",
        "\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test F1: {test_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VdvLXeyw_IP"
      },
      "source": [
        "## ResNet50\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_ok-lQhNzmj"
      },
      "source": [
        "### Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiGPZThvxDI1"
      },
      "outputs": [],
      "source": [
        "def train_custom_model_resnet50(unfreeze_layers, optimizer_fn, lr, **kwargs):\n",
        "    model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1) # Load ResNet50 instead of DeiT\n",
        "\n",
        "    # Get the number of layers in the ResNet50 model\n",
        "    num_layers = len(list(model.children()))\n",
        "\n",
        "    # Freeze all layers except the specified number of unfrozen layers\n",
        "    for i, child in enumerate(model.children()):\n",
        "        if i < num_layers - unfreeze_layers:\n",
        "            for param in child.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    num_classes = 4\n",
        "    in_features = model.fc.in_features  # Get the number of input features for the fully connected layer\n",
        "\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(0.3),\n",
        "        nn.BatchNorm1d(num_features=in_features),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(in_features, num_classes)\n",
        "    )\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define the loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optimizer_fn(model.parameters(), lr=lr, **kwargs)\n",
        "\n",
        "    # Define the learning rate scheduler\n",
        "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5, verbose=True)\n",
        "\n",
        "    # Early stopping parameters\n",
        "    early_stopping_patience = 10\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    n_batch_train = len(train_loader)\n",
        "    n_batch_val = len(val_loader)\n",
        "\n",
        "    num_epochs = 100\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        train_loss, train_correct, train_total, train_f1_total = 0.0, 0, 0, 0\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            train_correct += torch.sum(preds == labels.data)\n",
        "            train_total += labels.size(0)\n",
        "            train_f1_total += f1_score(labels.cpu().detach(), preds.cpu().detach(), average='weighted') * labels.size(0)\n",
        "\n",
        "        train_loss /= n_batch_train\n",
        "        train_acc = train_correct.item() / train_total\n",
        "        train_f1 = train_f1_total / train_total\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_correct, val_total, val_f1_total = 0.0, 0, 0, 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                val_correct += torch.sum(preds == labels.data)\n",
        "                val_total += labels.size(0)\n",
        "                val_f1_total += f1_score(labels.cpu().detach(), preds.cpu().detach(), average='weighted') * labels.size(0)\n",
        "\n",
        "        val_loss /= n_batch_val\n",
        "        val_acc = val_correct.item() / val_total\n",
        "        val_f1 = val_f1_total / val_total\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}],\\nTrain Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
        "\n",
        "        # Check for early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        if epochs_without_improvement >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered, stopping at epoch\", epoch)\n",
        "            break\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnUUHjSzR78k"
      },
      "source": [
        "### Model selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tSO3v82Qq24"
      },
      "outputs": [],
      "source": [
        "to_unfreeze = [0,1,3,5]\n",
        "lr_s = [0.001, 0.005, 0.01]\n",
        "optimizers = [optim.Adam, optim.SGD, optim.RMSprop, optim.Adagrad]\n",
        "\n",
        "for to_unfr in to_unfreeze:\n",
        "  for lr in lr_s:\n",
        "    for opt in optimizers:\n",
        "      print(\"Training ResNet50 with {} last layers unfrozen, lr {}, {}\".format(to_unfr, lr, str(opt)), end='\\n\\n')\n",
        "      train_custom_model_resnet50(to_unfr, opt, lr)\n",
        "      print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrE4Oz-GSCFI"
      },
      "source": [
        "### Actual model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmkxo2QmXSUL"
      },
      "outputs": [],
      "source": [
        "model = train_custom_model_resnet50(3, optim.Adagrad,  0.001, weight_decay=1e-4)\n",
        "torch.save(model.state_dict(), 'resnet_3_001_Adam_reg_deit_sets.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyiWFHZ5N56S"
      },
      "source": [
        "### Load model later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3u4IiGuLj02r"
      },
      "outputs": [],
      "source": [
        "custom_dataset = CustomDataset(pd.read_csv('green_dispersed_coords.csv'), './nl_svi_dispersed_green', transform=val_transforms)\n",
        "\n",
        "# Load the indices (when resuming)\n",
        "#train_indices = torch.load('test_indices_bins1_resnet.pt')\n",
        "val_indices = torch.load('val_indices_bins1_resnet.pt')\n",
        "test_indices = torch.load('test_indices_resnet.pt')\n",
        "\n",
        "# Create the datasets using the loaded indices\n",
        "#train_dataset = Subset(custom_dataset, train_indices)\n",
        "val_dataset = Subset(custom_dataset, val_indices)\n",
        "test_dataset = Subset(custom_dataset, test_indices)\n",
        "\n",
        "# Create data loaders\n",
        "#train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaQMlygDOBLS"
      },
      "outputs": [],
      "source": [
        "unfreeze_layers = 3\n",
        "num_classes = 4\n",
        "\n",
        "#Load the model and adjust the architecture\n",
        "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1) # Load ResNet50 instead of DeiT\n",
        "\n",
        "num_layers = len(list(model.children())) # Get the number of layers in the ResNet50 model\n",
        "\n",
        "for i, child in enumerate(model.children()): # Freeze all layers except the specified number of unfrozen layers\n",
        "    if i < num_layers - unfreeze_layers:\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "in_features = model.fc.in_features  # Get the number of input features for the fully connected layer\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0),\n",
        "    nn.BatchNorm1d(num_features=in_features),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0),\n",
        "    nn.Linear(in_features, num_classes)\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "#Load the weights\n",
        "model.load_state_dict(torch.load(\"resnet_3_Adagrad_01_reg.pth\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ7iwwCIAUra"
      },
      "source": [
        "### Evaluation on the test set\n",
        "\n",
        "We use the test set and the random prediction here for comparison, and we then visualize the images for all these predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wqLpva7Aef8"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "test_loss, test_correct, test_correct_adj, test_total, test_f1_total = 0.0, 0, 0, 0, 0\n",
        "model.eval()\n",
        "num_batches = len(test_loader)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        test_correct += torch.sum(preds == labels.data)\n",
        "        test_correct_adj += torch.sum(preds == labels.data)\n",
        "        test_correct_adj += torch.sum( (preds +1) == labels.data) #to compute adjusted acc, comment this for standard acc\n",
        "        test_correct_adj += torch.sum( (preds -1) == labels.data) #to compute adjusted acc, comment this for standard acc\n",
        "        test_total += labels.size(0)\n",
        "        test_f1_total += f1_score(labels.cpu().detach(), preds.cpu().detach(), average='weighted') * labels.size(0)\n",
        "\n",
        "test_loss /= num_batches\n",
        "test_acc = test_correct.item() / test_total\n",
        "test_acc_adj = test_correct_adj.item() / test_total\n",
        "test_f1 = test_f1_total / test_total\n",
        "\n",
        "print('Test performance of ResNet50')\n",
        "print(f'Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.5f}, Test Adj Acc: {test_acc_adj:.5f}, Test F1: {test_f1:.5f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGIDAbiaGjDN"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def imshow(img):\n",
        "    img = img * torch.tensor([0.229, 0.224, 0.225])[:, None, None] + torch.tensor([0.485, 0.456, 0.406])[:, None, None]  # Unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(30, 3))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "test_loss, test_correct, test_total, test_f1_total = 0.0, 0, 0, 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for batch_index, (inputs, labels) in enumerate(test_loader):\n",
        "    if batch_index == 0:  # Only take the first batch\n",
        "        inputs, labels = inputs[:10].to(device), labels[:10].to(device)  # Select the first 10 examples\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        test_correct += torch.sum(preds == labels.data)\n",
        "        test_total += labels.size(0)\n",
        "        test_f1_total += f1_score(labels.cpu().detach(), preds.cpu().detach(), average='weighted') * labels.size(0)\n",
        "        print('preds:', preds)\n",
        "        print('labels:',labels.data)\n",
        "\n",
        "        inputs_cpu = inputs.cpu()\n",
        "        imshow(torchvision.utils.make_grid(inputs_cpu, nrow=10))\n",
        "    else:\n",
        "      break\n",
        "\n",
        "test_loss /= test_total\n",
        "test_acc = test_correct.item() / test_total\n",
        "test_f1 = test_f1_total / test_total\n",
        "\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test F1: {test_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ttar75WxoD31"
      },
      "source": [
        "# Explaining\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5ji0TXANfcu"
      },
      "source": [
        "## Maybe useful plotting function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNLSoiz0O7px"
      },
      "outputs": [],
      "source": [
        "for batch_index, (i, l) in enumerate(test_loader):\n",
        "    if batch_index == 0:  # Only take the first batch\n",
        "        inputs, labels = i[:10].to(device), l[:10].to(device)  # Select the first 10 examples\n",
        "        print(len(inputs))\n",
        "        inp = inputs[1]\n",
        "        lab = labels[1]\n",
        "    else:\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9I0AokHPr_L"
      },
      "source": [
        "### To print one image or a grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf-8QOr6Okiq"
      },
      "outputs": [],
      "source": [
        "#%matplotlib inline\n",
        "\n",
        "def showGrid(img):\n",
        "    img = img * torch.tensor([0.229, 0.224, 0.225])[:, None, None] + torch.tensor([0.485, 0.456, 0.406])[:, None, None]  # Unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(30, 3))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def showIm(img):\n",
        "    img = img * torch.tensor([0.229, 0.224, 0.225])[:, None, None] + torch.tensor([0.485, 0.456, 0.406])[:, None, None]  # Unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOKjQ8b-P6xp"
      },
      "outputs": [],
      "source": [
        "print(labels)\n",
        "inputs_cpu = inputs.cpu()\n",
        "showGrid(torchvision.utils.make_grid(inputs_cpu, nrow=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQWmeki0PTN5"
      },
      "outputs": [],
      "source": [
        "print(\"Label:\", lab)\n",
        "inp = inp.to('cpu')\n",
        "showIm(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj8ds0lUPqfY"
      },
      "source": [
        "## Getting the top predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjdVcuRhpojU"
      },
      "outputs": [],
      "source": [
        "def get_extreme_indices():\n",
        "    extreme_indices = []\n",
        "    logits = []\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_index, (inputs, labels) in enumerate(test_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            correct_predictions = (preds == labels.data)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "            for i, is_correct in enumerate(correct_predictions):\n",
        "                if is_correct:\n",
        "                    # Compute the index of the sample in the dataset\n",
        "                    sample_index = batch_index * test_loader.batch_size + i\n",
        "                    correct_class = labels[i].item()\n",
        "                    # Store the index, correct class, and corresponding logit in a tuple\n",
        "                    correct_logit = outputs[i, labels[i]].item()\n",
        "                    extreme_indices.append((sample_index, correct_class, correct_logit))\n",
        "                    # Store the logit corresponding to the correct prediction\n",
        "                    logits.append(correct_logit)\n",
        "\n",
        "    # Create the confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # Sort the tuples based on the most extreme logits\n",
        "    sorted_tuples = sorted(extreme_indices, key=lambda x: abs(x[2]), reverse=True)\n",
        "    return sorted_tuples, cm\n",
        "\n",
        "model.eval()\n",
        "extreme_tuples, cm = get_extreme_indices()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHz0On19tLnR"
      },
      "outputs": [],
      "source": [
        "print(extreme_tuples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf09I4MJuSfq"
      },
      "outputs": [],
      "source": [
        "with open('extreme_deit_deit.pkl', 'wb') as f:\n",
        "    pickle.dump(extreme_tuples, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCEDSPSmg4pB"
      },
      "outputs": [],
      "source": [
        "with open('extreme_resnet.pkl', 'rb') as f:\n",
        "    extreme_tuples = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgCjodxNWD8T"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, name):\n",
        "    tick_names = ['very low', 'low', 'moderate', 'high&v. high']\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 16})  # Increase label size here\n",
        "    plt.xticks(ticks=[0.5, 1.5, 2.5, 3.5], labels=tick_names, fontsize=14)  # Set x-axis tick names\n",
        "    plt.yticks(ticks=[0.5, 1.5, 2.5, 3.5], labels=tick_names, fontsize=14)  # Set y-axis tick names\n",
        "    plt.xlabel('Predicted', fontsize=20)  # Increase x-axis label size\n",
        "    plt.ylabel('Truth', fontsize=20)  # Increase y-axis label size\n",
        "    cbar = ax.collections[0].colorbar\n",
        "    cbar.ax.tick_params(labelsize=14)\n",
        "    plt.tight_layout()  # Remove margins\n",
        "    plt.savefig(name + '.eps', bbox_inches='tight')  # Save with tight bounding box\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njmsKSAZWGc1"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(cm,'conf_deit')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuCsii3GqwZM"
      },
      "outputs": [],
      "source": [
        "def get_top_images_per_category(indices, top_n=10):\n",
        "    top_images = {i: [] for i in range(4)}\n",
        "    for index, class_num, logit in indices:\n",
        "        if len(top_images[class_num]) < top_n:\n",
        "            top_images[class_num].append(index)\n",
        "        if all(len(images) >= top_n for images in top_images.values()):\n",
        "            break\n",
        "    return top_images\n",
        "\n",
        "top_n = 10\n",
        "top_images_per_category = get_top_images_per_category(extreme_tuples, top_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNVSXhGZegmU"
      },
      "outputs": [],
      "source": [
        "for class_num, image_indices in top_images_per_category.items():\n",
        "    print(f\"Top {top_n} images for class {class_num}:\")\n",
        "    for index in image_indices:\n",
        "        image_t, target = test_dataset[index]\n",
        "        showIm(image_t)\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qangR5B0PlKg"
      },
      "source": [
        "## SHAP\n",
        "\n",
        "https://github.com/shap/shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvaquNBnPxWI"
      },
      "outputs": [],
      "source": [
        "#just like with timm, you need to install this every time when you work in the cloud\n",
        "!pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oRzDaw1YO4k"
      },
      "outputs": [],
      "source": [
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhlbWh5pqSGB"
      },
      "outputs": [],
      "source": [
        "for class_num, image_indices in top_images_per_category.items():\n",
        "  print(class_num)\n",
        "  print(image_indices)\n",
        "  print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-NSSnVqeLDY"
      },
      "outputs": [],
      "source": [
        "to_explain= []\n",
        "\n",
        "for class_num, image_indices in top_images_per_category.items():\n",
        "    for index in image_indices:\n",
        "        image_t, target = test_dataset[index]\n",
        "        to_explain.append(image_t)\n",
        "\n",
        "to_explain = torch.stack(to_explain).cuda()\n",
        "\n",
        "def normalize(tensor):\n",
        "    tensor_min = tensor.min()\n",
        "    tensor_max = tensor.max()\n",
        "    return (tensor - tensor_min) / (tensor_max - tensor_min)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OXT3dpPZFoL"
      },
      "outputs": [],
      "source": [
        "class_names = [\"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\"]\n",
        "model.eval()\n",
        "\n",
        "# Use GradientExplainer\n",
        "background_indices = np.random.choice(len(test_dataset), 50, replace=False)\n",
        "background = torch.stack([test_dataset[i][0] for i in background_indices]).cuda()\n",
        "e = shap.GradientExplainer(model, background)\n",
        "\n",
        "shap_values,indexes = e.shap_values(to_explain, ranked_outputs=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QNfulu5Fh-de"
      },
      "outputs": [],
      "source": [
        "# Get the names for the classes\n",
        "index_names = np.vectorize(lambda x: class_names[x])(indexes.cpu())\n",
        "\n",
        "#prepare the data to comply with the expectations of the plotting function\n",
        "to_explain = to_explain.permute(0, 2, 3, 1)\n",
        "shap_values = [np.transpose(sv, (0, 2, 3, 1)) for sv in shap_values]\n",
        "to_explain_norm = normalize(to_explain)\n",
        "\n",
        "# plot the explanations\n",
        "shap.image_plot(shap_values, to_explain_norm.cpu().numpy(), index_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EVIZO2hT6_Cl"
      },
      "outputs": [],
      "source": [
        "# To save\n",
        "torch.save(shap_values, 'shap_values_resnet_4.pt')\n",
        "torch.save(indexes, 'indexes_resnet_4.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSCR3TB07BJ4"
      },
      "outputs": [],
      "source": [
        "# To load\n",
        "shap_values = torch.load('shap_values.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6LAyZHWBYkB"
      },
      "source": [
        "## Gradient rollout\n",
        "\n",
        "Gradient rollout was performed on the local CPU, not in the cloud. The code below would work on a PC, but not on cloud service.\n",
        "\n",
        "**The code assumes you cloned Gildenblat's repository. Before running the code, go to ./vit-explain , inside the functions, and change the path to the model to the path where you saved the trained model, and re-create the model there if you only saved  weights (like this code generally does). There is code for re-creating the model in this notebook in sub-section DeiT/To load later. If you adjusted anything in the architecture of the model, it should also be adjusted there where it re-builds the model before it loads the weights.**\n",
        "\n",
        "The application of Gradient Rollout to DeiT models is courtesy of J. Gildenblat. https://jacobgil.github.io/deeplearning/vision-transformer-explainability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9Qq8jM5D4OQ"
      },
      "outputs": [],
      "source": [
        "os.chdir('./vit-explain')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acB9l2TLD441"
      },
      "outputs": [],
      "source": [
        "for class_num, dat in top_images_per_category.items():\n",
        "    print(f\"Top {top_n} images for class {class_num}\")\n",
        "    for index, logit in dat:\n",
        "        original_index = test_indices[index]\n",
        "        img_name = test_dataset.dataset.get_img_name(original_index)\n",
        "        img_name = '../nl_svi_dispersed_green/'+img_name\n",
        "        !python vit_explain.py --image_path {img_name} --head_fusion mean --discard_ratio 0.8 --logit {logit} --cl {class_num}\n",
        "        !python vit_explain.py --image_path {img_name} --head_fusion max --discard_ratio 0.8 --logit {logit} --cl {class_num}\n",
        "        !python vit_explain.py --image_path {img_name} --head_fusion min --discard_ratio 0.8 --logit {logit} --cl {class_num}\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl9yXeKsEMk3"
      },
      "source": [
        "### And with the least certain predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxL39RMsEQnY"
      },
      "outputs": [],
      "source": [
        "extreme_tuples.reverse()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbhfPDjYESOQ"
      },
      "outputs": [],
      "source": [
        "def get_bottom_images_per_category(indices, n=10):\n",
        "    b_images = defaultdict(list)\n",
        "    for index, class_num, logit in indices:\n",
        "        if len(b_images[class_num]) < n:\n",
        "            b_images[class_num].append((index, logit))\n",
        "\n",
        "    return b_images\n",
        "\n",
        "bottom_n = 10\n",
        "b_images_per_category = get_bottom_images_per_category(extreme_tuples,bottom_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z17aCIL4EXa3"
      },
      "outputs": [],
      "source": [
        "for class_num, dat in b_images_per_category.items():\n",
        "    print(f\"Bottom {bottom_n} images for class {class_num}\")\n",
        "    for index, logit in dat:\n",
        "        original_index = test_indices[index]\n",
        "        img_name = test_dataset.dataset.get_img_name(original_index)\n",
        "        img_name = '../nl_svi_green_10000/'+img_name\n",
        "        !python vit_explain.py --image_path {img_name} --head_fusion mean --discard_ratio 0.8 --logit {logit} --cl {class_num}\n",
        "        !python vit_explain.py --image_path {img_name} --head_fusion max --discard_ratio 0.8 --logit {logit} --cl {class_num}\n",
        "        !python vit_explain.py --image_path {img_name} --head_fusion min --discard_ratio 0.8 --logit {logit} --cl {class_num}\n",
        "    print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "IOcXy2_xKkRH",
        "dK1DhFQOlun8",
        "8x8ZeaqsKoxb",
        "vdnaVwaG7Gwk",
        "X4XLe1fGAAQR",
        "U41Nkm3yuGTf",
        "T9BzXT5_R58M",
        "Hya1mLBsWD8m",
        "-dA7UK6IVydw",
        "QFr0Mtk5OADL",
        "nBTcPVGyHR7A",
        "2oBZzwqmODsJ",
        "bX1yYtYLOTLB",
        "MXVXn6L8yzk2",
        "84SPSSd8OG38",
        "YKGInk1bOKYK",
        "6VdvLXeyw_IP",
        "z_ok-lQhNzmj",
        "rnUUHjSzR78k",
        "BrE4Oz-GSCFI",
        "vyiWFHZ5N56S",
        "CJ7iwwCIAUra",
        "Ttar75WxoD31",
        "b5ji0TXANfcu",
        "xj8ds0lUPqfY",
        "qangR5B0PlKg",
        "f6LAyZHWBYkB",
        "Vl9yXeKsEMk3"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}